{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "734759c8-22e4-4a89-80ca-0f51071affbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "\n",
    "# ========== USER CONFIG ==========\n",
    "INPUT_DIR = \"data\"   # folder with your Excel files\n",
    "VALID_EXTS = {\".xlsx\", \".xlsm\", \".xls\"}  # add .xlsb if needed (requires pyxlsb)\n",
    "SCAN_ROWS = 20  # how many rows to search for header\n",
    "TARGET_COLUMNS = [\n",
    "        'JobNumber', 'Office', 'Office (Div)', 'ProjectTitle', 'Client', \n",
    "        'Location (Country)', 'Gross Fee (USD)', 'Fee Earned (USD)', \n",
    "        'Gross Fee Yet To Be Earned (USD)', 'Currency', 'GrossFee', \n",
    "        'GrossFeeEarned', 'GrossFeeYetToBeEarned', 'Status', 'NewProject', \n",
    "        'StartDate', 'Anticipated EndDate', 'ProjectType'\n",
    "    ]\n",
    "\n",
    "COLUMN_ALIASES = {\n",
    "    'Location (Country)': ['Location (Country)', 'Location', 'Country'],\n",
    "    'NewProject': ['NewProject', 'New Project', 'New_Project', 'IsNew', 'Is New'],\n",
    "}\n",
    "\n",
    "def list_excel_files(folder: str, exts=VALID_EXTS) -> List[str]:\n",
    "    files = []\n",
    "    for root, _, filenames in os.walk(folder):\n",
    "        for fn in filenames:\n",
    "            if os.path.splitext(fn)[1].lower() in exts:\n",
    "                files.append(os.path.join(root, fn))\n",
    "    return files\n",
    "\n",
    "def normalize(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize column names so:\n",
    "    - 'Project Title' -> 'projecttitle'\n",
    "    - 'ProjectTitle'  -> 'projecttitle'\n",
    "    - 'Project_Type'  -> 'projecttype'\n",
    "    - 'Client'        -> 'client'\n",
    "    - 'Gross Fee Yet To Be Earned (USD)' -> 'grossfeeyettobeearnedusd'\n",
    "    \"\"\"\n",
    "    if name is None or type(name) is not str:\n",
    "        return \"\"\n",
    "    s = name.strip().lower()\n",
    "    s = re.sub(r\"[\\s_\\-]+\", \"\", s)     # remove spaces/underscores/dashes\n",
    "    s = re.sub(r\"[^\\w]\", \"\", s)        # remove other punctuation\n",
    "    return s\n",
    "\n",
    "def find_header_row(df_no_header):\n",
    "    \"\"\"\n",
    "    Return the earliest (0-based) row index where BOTH 'Client' and 'Currency' appear.\n",
    "    Case-insensitive; whitespace/punct ignored.\n",
    "    \"\"\"\n",
    "    import builtins\n",
    "    max_r = min(len(df_no_header), SCAN_ROWS)\n",
    "    for r in range(max_r):\n",
    "        row = [normalize(v) for v in df_no_header.iloc[r].tolist()]\n",
    "        if \"jobnumber\" in row and \"currency\" in row:\n",
    "            return r\n",
    "    return None  # not found\n",
    "\n",
    "def _to_number(series: pd.Series) -> pd.Series:\n",
    "    # Keep digits, sign, and decimal; turn \"(123)\" into \"-123\"\n",
    "    s = series.astype(str).fillna(\"\")\n",
    "    s = s.str.replace(r\"\\(([\\d\\.,]+)\\)\", r\"-\\1\", regex=True)\n",
    "    s = s.str.replace(r\"[^\\d\\.\\-]\", \"\", regex=True)\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def read_sheet(path, sheet):\n",
    "    raw = pd.read_excel(path, sheet_name=sheet, header=None, dtype=str, engine=None)\n",
    "    print(f\"Processing sheet : {sheet}\")\n",
    "    if raw.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    hdr = find_header_row(raw)\n",
    "    if hdr is None:\n",
    "        print(f\"no headers found for {sheet} - skipping..\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    cols = raw.iloc[hdr].tolist()\n",
    "    \n",
    "    # Clean up column names\n",
    "    cleaned_cols = []\n",
    "    seen_cols = {}\n",
    "    \n",
    "    for i, col in enumerate(cols):\n",
    "        if col is None or (isinstance(col, float) and pd.isna(col)) or str(col).strip() == '':\n",
    "            clean_col = f\"unnamed_col_{i}\"\n",
    "        else:\n",
    "            clean_col = str(col).strip()\n",
    "        \n",
    "        if clean_col in seen_cols:\n",
    "            seen_cols[clean_col] += 1\n",
    "            clean_col = f\"{clean_col}_duplicate_{seen_cols[clean_col]}\"\n",
    "        else:\n",
    "            seen_cols[clean_col] = 0\n",
    "        \n",
    "        cleaned_cols.append(clean_col)\n",
    "    \n",
    "    data = raw.iloc[hdr+1:].reset_index(drop=True)\n",
    "    data.columns = cleaned_cols\n",
    "    \n",
    "    print(f\"Columns in sheet {sheet} : {cleaned_cols}\")\n",
    "    \n",
    "    # Create normalized mapping: normalized name -> actual column name\n",
    "    normalized_map = {}\n",
    "    for actual_col in data.columns:\n",
    "        normalized_map[normalize(actual_col)] = actual_col\n",
    "    \n",
    "    out = pd.DataFrame()\n",
    "    \n",
    "    # Map each target column, checking aliases\n",
    "    for target_col in TARGET_COLUMNS:\n",
    "        found = False\n",
    "        matched_col = None\n",
    "        \n",
    "        # Check if this column has aliases\n",
    "        if target_col in COLUMN_ALIASES:\n",
    "            possible_names = COLUMN_ALIASES[target_col]\n",
    "        else:\n",
    "            possible_names = [target_col]\n",
    "        \n",
    "        # Try to find any of the possible names\n",
    "        for possible_name in possible_names:\n",
    "            normalized_possible = normalize(possible_name)\n",
    "            if normalized_possible in normalized_map:\n",
    "                actual_col = normalized_map[normalized_possible]\n",
    "                out[target_col] = data[actual_col]\n",
    "                matched_col = actual_col\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        if found:\n",
    "            print(f\"✓ Found: {target_col} (mapped from '{matched_col}')\")\n",
    "        else:\n",
    "            print(f\"✗ Missing: {target_col} (tried: {', '.join(possible_names)})\")\n",
    "    \n",
    "    # Ensure the DataFrame has ONLY the target columns in the exact order\n",
    "    out = out.reindex(columns=TARGET_COLUMNS)\n",
    "    \n",
    "    if out.empty:\n",
    "        print(f\"No valid data found in {sheet}\")\n",
    "        return pd.DataFrame(columns=TARGET_COLUMNS)\n",
    "\n",
    "    # Convert numeric columns\n",
    "    numeric_columns = [\n",
    "        'Gross Fee (USD)', 'Fee Earned (USD)', 'Gross Fee Yet To Be Earned (USD)',\n",
    "        'GrossFee', 'GrossFeeEarned', 'GrossFeeYetToBeEarned'\n",
    "    ]\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        if col in out.columns and not out[col].isna().all():\n",
    "            try:\n",
    "                out[col] = _to_number(out[col])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    print(f\"Successfully processed {sheet}: {len(out)} rows\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def read_file(path):\n",
    "    \"\"\"Read all sheets from an Excel file.\"\"\"\n",
    "    # Convert volume path to proper format for pandas\n",
    "    if path.startswith('/Volumes/'):\n",
    "        # Volume paths are already accessible as local filesystem paths\n",
    "        local_path = path\n",
    "    elif path.startswith('dbfs:/Volumes/'):\n",
    "        # Remove dbfs: prefix\n",
    "        local_path = path.replace('dbfs:', '')\n",
    "    else:\n",
    "        local_path = path\n",
    "    \n",
    "    print(f\"Attempting to read from: {local_path}\")\n",
    "    \n",
    "    try:\n",
    "        xl = pd.ExcelFile(local_path, engine='openpyxl')\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read file: {e}\")\n",
    "        print(f\"Path attempted: {local_path}\")\n",
    "        return pd.DataFrame(columns=TARGET_COLUMNS)\n",
    "    \n",
    "    wb = openpyxl.load_workbook(local_path, read_only=True, data_only=True)\n",
    "    \n",
    "    # Filter out hidden sheets\n",
    "    visible_sheets = []\n",
    "    for sheet_name in xl.sheet_names:\n",
    "        sheet = wb[sheet_name]\n",
    "        # sheet.sheet_state can be 'visible', 'hidden', or 'veryHidden'\n",
    "        if sheet.sheet_state == 'visible':\n",
    "            visible_sheets.append(sheet_name)\n",
    "        else:\n",
    "            print(f\"Skipping hidden sheet: {sheet_name}\")\n",
    "    \n",
    "    wb.close()\n",
    "\n",
    "    frames = []\n",
    "    for s in visible_sheets:\n",
    "        try:\n",
    "            df = read_sheet(local_path, s)\n",
    "            if not df.empty:\n",
    "                frames.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading sheet {s}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not frames:\n",
    "        return pd.DataFrame(columns=TARGET_COLUMNS)\n",
    "    \n",
    "    return pd.concat(frames, ignore_index=True)\n",
    "\n",
    "\n",
    "def extract_all(input_dir=INPUT_DIR):\n",
    "    dfs = []\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for f in files:\n",
    "            if os.path.splitext(f)[1].lower() in VALID_EXTS:\n",
    "                dfs.append(read_file(os.path.join(root, f)))\n",
    "    return pd.concat(dfs, ignore_index=True)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data_extraction",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
