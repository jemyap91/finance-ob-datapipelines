{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efaf3d6e-e036-45df-bd7e-397503d1cdbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Silver Layer - Data Cleaning and Transformation\n",
    "This notebook reads from the bronze layer and creates a cleaned, validated silver layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77198a46-d6ae-49ed-aff7-5f90455e3737",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col, trim, upper, lower, when, coalesce, \n",
    "    to_date, datediff, current_date, year, month,\n",
    "    regexp_replace, round as spark_round\n",
    ")\n",
    "from pyspark.sql.types import DecimalType\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4906b0a-9846-41e0-ada2-d5feaaa1f97d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Configuration\n",
    "CATALOG_NAME = \"orderbooks_main\"\n",
    "BRONZE_SCHEMA = \"bronze\"\n",
    "SILVER_SCHEMA = \"silver\"\n",
    "BRONZE_TABLE = \"orderbook\"\n",
    "SILVER_TABLE = \"orderbook_clean\"\n",
    "\n",
    "print(f\"Building Silver Layer\")\n",
    "print(f\"Source: {CATALOG_NAME}.{BRONZE_SCHEMA}.{BRONZE_TABLE}\")\n",
    "print(f\"Target: {CATALOG_NAME}.{SILVER_SCHEMA}.{SILVER_TABLE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82b6499a-c61c-4851-adc5-d678134c2200",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create silver schema if it doesn't exist\n",
    "spark.sql(f\"USE CATALOG {CATALOG_NAME}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {SILVER_SCHEMA}\")\n",
    "print(f\"✓ Schema {SILVER_SCHEMA} ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a287da2-bc37-406c-98b3-4f301558dba3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read from bronze layer\n",
    "bronze_table_path = f\"{CATALOG_NAME}.{BRONZE_SCHEMA}.{BRONZE_TABLE}\"\n",
    "df_bronze = spark.table(bronze_table_path)\n",
    "\n",
    "print(f\"✓ Loaded {df_bronze.count():,} rows from bronze layer\")\n",
    "print(f\"\\nBronze Schema:\")\n",
    "df_bronze.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7db4ef99-3e2e-46bd-b3ed-c947a8ffbf1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Preview bronze data\n",
    "df_bronze.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67d5343f-250c-4983-bdec-e59db9ee8d18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_bronze.orderBy(\"anticipated_end_date\").display(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45d41622-ed05-4778-8be9-f2bdf8bbe775",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "null_anticipated_end_dates = df_bronze.filter(col(\"anticipated_end_date\").isNull())\n",
    "\n",
    "null_anticipated_end_dates.groupby(\"Office\").count().orderBy(\"count\", ascending=False).display()\n",
    "# Check for null values in critical columns\n",
    "# critical_columns = ['JobNumber', 'ProjectTitle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36046887-3517-4870-9192-6a8727e1e750",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc4b985c-0207-48c0-9b46-6f52961ed211",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check for duplicates based on row_hash\n",
    "total_rows = df_bronze.count()\n",
    "unique_rows = df_bronze.select(\"row_hash\").distinct().count()\n",
    "duplicates = total_rows - unique_rows\n",
    "\n",
    "print(f\"Data Quality Summary:\")\n",
    "print(f\"  Total rows: {total_rows:,}\")\n",
    "print(f\"  Unique rows: {unique_rows:,}\")\n",
    "print(f\"  Duplicates: {duplicates:,}\")\n",
    "\n",
    "# Check for null values in critical columns\n",
    "critical_columns = ['JobNumber', 'ProjectTitle', 'Client', 'Office']\n",
    "print(f\"\\nNull counts in critical columns:\")\n",
    "for col_name in critical_columns:\n",
    "    null_count = df_bronze.filter(col(col_name).isNull()).count()\n",
    "    print(f\"  {col_name}: {null_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c5e7012-8789-4151-92c4-0a899d320a53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de77da54-578b-4b44-9766-c4b84b8c3e4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Start transformations\n",
    "df_silver = df_bronze\n",
    "\n",
    "# 1. Remove duplicates (keep first occurrence based on row_hash)\n",
    "df_silver = df_silver.dropDuplicates(['row_hash'])\n",
    "print(f\"✓ Removed duplicates: {df_silver.count():,} rows remaining\")\n",
    "\n",
    "# 2. Clean and standardize string columns\n",
    "string_columns = ['JobNumber', 'Office', 'office_div', 'ProjectTitle', \n",
    "                  'Client', 'location_country', 'Currency', 'Status', 'ProjectType']\n",
    "\n",
    "for col_name in string_columns:\n",
    "    df_silver = df_silver.withColumn(\n",
    "        col_name,\n",
    "        trim(col(col_name))\n",
    "    )\n",
    "\n",
    "print(f\"✓ Cleaned string columns\")\n",
    "\n",
    "# 3. Standardize Status values\n",
    "df_silver = df_silver.withColumn(\n",
    "    'Status',\n",
    "    upper(trim(col('Status')))\n",
    ")\n",
    "\n",
    "# 4. Ensure NewProject is properly set (1 or 0)\n",
    "df_silver = df_silver.withColumn(\n",
    "    'NewProject',\n",
    "    when(col('NewProject').isNull(), 0)\n",
    "    .otherwise(col('NewProject'))\n",
    ")\n",
    "\n",
    "print(f\"✓ Standardized categorical values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34ceb72b-c232-4e0b-8902-0f449aa88784",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. Calculate derived fields\n",
    "\n",
    "# Calculate project duration in days (if both dates exist)\n",
    "df_silver = df_silver.withColumn(\n",
    "    'project_duration_days',\n",
    "    when(\n",
    "        (col('StartDate').isNotNull()) & (col('anticipated_end_date').isNotNull()),\n",
    "        datediff(col('anticipated_end_date'), col('StartDate'))\n",
    "    ).otherwise(None)\n",
    ")\n",
    "\n",
    "# Calculate days until project end (from current date)\n",
    "df_silver = df_silver.withColumn(\n",
    "    'days_until_end',\n",
    "    when(\n",
    "        col('anticipated_end_date').isNotNull(),\n",
    "        datediff(col('anticipated_end_date'), current_date())\n",
    "    ).otherwise(None)\n",
    ")\n",
    "\n",
    "# Calculate fee completion percentage\n",
    "df_silver = df_silver.withColumn(\n",
    "    'fee_completion_pct',\n",
    "    when(\n",
    "        (col('gross_fee_usd').isNotNull()) & (col('gross_fee_usd') > 0),\n",
    "        spark_round((col('fee_earned_usd') / col('gross_fee_usd')) * 100, 2)\n",
    "    ).otherwise(None)\n",
    ")\n",
    "\n",
    "# Determine if project is active, completed, or upcoming\n",
    "df_silver = df_silver.withColumn(\n",
    "    'project_status_derived',\n",
    "    when(\n",
    "        col('days_until_end') < 0, 'COMPLETED'\n",
    "    ).when(\n",
    "        (col('days_until_end') >= 0) & (col('fee_earned_usd') > 0), 'ACTIVE'\n",
    "    ).when(\n",
    "        (col('days_until_end') >= 0) & (col('fee_earned_usd').isNull() | (col('fee_earned_usd') == 0)), 'UPCOMING'\n",
    "    ).otherwise('UNKNOWN')\n",
    ")\n",
    "\n",
    "print(f\"✓ Calculated derived fields\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2cfea50-1524-4ce2-9a58-70c4b7043dfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 6. Add data quality flags\n",
    "\n",
    "df_silver = df_silver.withColumn(\n",
    "    'is_valid_record',\n",
    "    when(\n",
    "        (col('JobNumber').isNotNull()) & \n",
    "        (col('ProjectTitle').isNotNull()) & \n",
    "        (col('Client').isNotNull()) & \n",
    "        (col('Office').isNotNull()),\n",
    "        True\n",
    "    ).otherwise(False)\n",
    ")\n",
    "\n",
    "# Flag records with financial inconsistencies\n",
    "df_silver = df_silver.withColumn(\n",
    "    'has_financial_issues',\n",
    "    when(\n",
    "        (col('gross_fee_usd').isNotNull()) & \n",
    "        (col('fee_earned_usd').isNotNull()) & \n",
    "        (col('gross_fee_yet_to_be_earned_usd').isNotNull()) &\n",
    "        (col('gross_fee_usd') != (col('fee_earned_usd') + col('gross_fee_yet_to_be_earned_usd'))),\n",
    "        True\n",
    "    ).otherwise(False)\n",
    ")\n",
    "\n",
    "print(f\"✓ Added data quality flags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0609f9d4-e42f-4c25-921f-a565805470e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Quality Checks on Silver Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07ef2d8a-bc02-4d20-b19d-c9d2df5a3430",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(f\"\\nSilver Layer Summary:\")\n",
    "print(f\"  Total rows: {df_silver.count():,}\")\n",
    "print(f\"  Valid records: {df_silver.filter(col('is_valid_record') == True).count():,}\")\n",
    "print(f\"  Records with financial issues: {df_silver.filter(col('has_financial_issues') == True).count():,}\")\n",
    "\n",
    "print(f\"\\nProject Status Distribution:\")\n",
    "df_silver.groupBy('project_status_derived').count().orderBy('count', ascending=False).show()\n",
    "\n",
    "print(f\"\\nOffice Distribution:\")\n",
    "df_silver.groupBy('Office').count().orderBy('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "342abaf2-9778-499a-a053-87f9d471ff06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Preview transformed data\n",
    "display(df_silver.select(\n",
    "    'JobNumber', 'ProjectTitle', 'Client', 'Office',\n",
    "    'gross_fee_usd', 'fee_earned_usd', 'fee_completion_pct',\n",
    "    'project_status_derived', 'days_until_end',\n",
    "    'is_valid_record', 'has_financial_issues'\n",
    ").limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7da12ba2-5ea0-4d81-9c93-191121205a98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Write to Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3f2195a-afeb-4da1-9e74-c4c7483fbf0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write to silver table\n",
    "silver_table_path = f\"{CATALOG_NAME}.{SILVER_SCHEMA}.{SILVER_TABLE}\"\n",
    "\n",
    "try:\n",
    "    df_silver.write.mode(\"overwrite\").saveAsTable(silver_table_path)\n",
    "    \n",
    "    final_count = spark.table(silver_table_path).count()\n",
    "    \n",
    "    print(f\"\\n✓ SUCCESS!\")\n",
    "    print(f\"✓ Data written to: {silver_table_path}\")\n",
    "    print(f\"✓ Total records in silver table: {final_count:,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error writing to silver layer: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66fadb6f-3cb0-4bf3-9622-823d06743fee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verify the silver table\n",
    "print(f\"\\nSilver Table Schema:\")\n",
    "spark.table(silver_table_path).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de408797-beef-4a89-98e2-7afbdcce12ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "build_silver_layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
